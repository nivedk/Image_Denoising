{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M-WSuLgoXf77"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QOn0Az97gesl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Otz47e6OsXO2"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "oBXwtm37sEXm",
    "outputId": "472aa34a-6639-4df7-d43f-ecffdfe1993a"
   },
   "outputs": [],
   "source": [
    "#pip install -q -U 'tensorboard<2.2.0,>=2.1.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r5LcfD_hsxPS"
   },
   "source": [
    "Especifica las direcciones donde se encuentran los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HfO67voAchG-"
   },
   "outputs": [],
   "source": [
    "PATH = \"/content/drive/My Drive/Colab Notebooks/IDCGAN_Github/Single-Image-De-Raining-Keras/dataset/rain\"\n",
    "folders = ['training','val','test_syn']\n",
    "\n",
    "INPATH = PATH+'/'+folders[0]\n",
    "VALNPATH = PATH+'/'+folders[1]\n",
    "TESTPATH = PATH+'/'+folders[2]\n",
    "CHECKPOINT = \"/content/drive/My Drive/Colab Notebooks/IDCGAN_Github/Single-Image-De-Raining-Keras/dataset/checkpoint/\"\n",
    "\n",
    "train_urls = !ls -1 \"{INPATH}\"\n",
    "val_urls = !ls -1 \"{VALNPATH}\"\n",
    "test_imgurls = !ls -1 \"{TESTPATH}\"\n",
    "\n",
    "INP = [INPATH+'/'+i for i in train_urls]\n",
    "VALP = [VALNPATH+'/'+i for i in val_urls]\n",
    "TESTP = [TESTPATH+'/'+i for i in test_imgurls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "01qBtBbxW0kf"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 400\n",
    "BATCH_SIZE = 1\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jvs366JZtBVY"
   },
   "source": [
    "Funcion para cargar las imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xkhFIFgDW6DG"
   },
   "outputs": [],
   "source": [
    "def load(path_to_image):\n",
    "  image = tf.io.read_file(path_to_image)\n",
    "  image = tf.io.decode_jpeg(image)\n",
    "\n",
    "  real = image[:,:tf.shape(image)[1]//2,:]\n",
    "  fake = image[:,tf.shape(image)[1]//2:,:]\n",
    "\n",
    "  real = tf.cast(real,tf.float32)\n",
    "  fake = tf.cast(fake,tf.float32)\n",
    "  \n",
    "  return fake, real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rMVAi0yNUXGu"
   },
   "outputs": [],
   "source": [
    "path_to_im = '/content/drive/My Drive/Colab Notebooks/IDCGAN_Github/Single-Image-De-Raining-Keras/dataset/rain/train/1.jpg'\n",
    "fake, real = load(path_to_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "colab_type": "code",
    "id": "avtfU4V7T-3s",
    "outputId": "68aa8bac-60f0-47f6-8762-0cb530bdf48d"
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(nrows=1,ncols=2)\n",
    "ax[1].imshow(real/255.0)\n",
    "ax[0].imshow(fake/255.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RcAJuW34UBui"
   },
   "outputs": [],
   "source": [
    "def resize(image_input,image_real,h,w):\n",
    "  image_input = tf.image.resize(image_input,(h,w),method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "  image_real = tf.image.resize(image_real,(h,w),method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "  return image_input, image_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "cxuatBugLRhX",
    "outputId": "fdfe10fc-e125-47df-f55b-353b4f406e6d"
   },
   "outputs": [],
   "source": [
    "print(fake.shape)\n",
    "fake, hhhhh= resize(fake,fake,256,256)\n",
    "print(fake.shape)\n",
    "print(hhhhh.shape)\n",
    "fig,ax = plt.subplots(nrows=1,ncols=2)\n",
    "ax[1].imshow(hhhhh/255.0)\n",
    "ax[0].imshow(fake/255.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MZhNimobl9Xv"
   },
   "outputs": [],
   "source": [
    "def random_crop(input_image, real_image):\n",
    "  stacked_image = tf.stack([input_image, real_image],axis=0)\n",
    "  cropped_image = tf.image.random_crop(stacked_image,size=(2,IMG_HEIGHT,IMG_WIDTH,3))\n",
    "  return cropped_image[0], cropped_image[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8OHeQHCen5Y5"
   },
   "outputs": [],
   "source": [
    "def normalize(input_image, real_image):\n",
    "  input_image = input_image/(255/2) - 1\n",
    "  real_image = real_image/(255/2) - 1\n",
    "  return input_image, real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "orVCDX2NwimS"
   },
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def random_jitter(input_image,real_image):\n",
    "  input_image, real_image = resize(input_image, real_image,286,286) # resizing to 286 x 286 x 3\n",
    "  input_image, real_image = random_crop(input_image, real_image) # randomly cropping to 256 x 256 x 3\n",
    "  if np.random.uniform()>0.5: # random mirroring\n",
    "    input_image = tf.image.flip_left_right(input_image)\n",
    "    real_image = tf.image.flip_left_right(real_image)\n",
    "  return input_image, real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "j7hqz-DiPRlQ",
    "outputId": "cd5a2312-2006-4fbc-d909-4ac38a93772e"
   },
   "outputs": [],
   "source": [
    "#real, fake = tf.map_fn(lambda path: load(path),path_to_im,)\n",
    "in_im,re_im = random_jitter(fake, real)\n",
    "fig,ax = plt.subplots(nrows=1,ncols=2)\n",
    "ax[1].imshow(re_im/255.0)\n",
    "ax[0].imshow(in_im/255.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uwJbrTsMLOPs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "El9qW3H0P02Q"
   },
   "outputs": [],
   "source": [
    "def load_train(image_path):\n",
    "  input_image, real_image = load(image_path)\n",
    "  input_image, real_image = random_jitter(input_image, real_image)\n",
    "  input_image, real_image = normalize(input_image, real_image)\n",
    "  return input_image, real_image\n",
    "\n",
    "def load_test(image_path):\n",
    "  input_image, real_image = load(image_path)\n",
    "  input_image, real_image = resize(input_image, real_image,IMG_HEIGHT, IMG_WIDTH)\n",
    "  input_image, real_image = normalize(input_image, real_image)\n",
    "  return input_image, real_image\n",
    "\n",
    "def load_validation(image_path):\n",
    "  return load_test(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iIEM7DcGQciX"
   },
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.list_files('/content/drive/My Drive/Colab Notebooks/IDCGAN_Github/Single-Image-De-Raining-Keras/dataset/rain/train/*.jpg')\n",
    "train_data = train_data.map(load_train,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "train_data = train_data.shuffle(BATCH_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "vali_data = tf.data.Dataset.list_files('/content/drive/My Drive/Colab Notebooks/IDCGAN_Github/Single-Image-De-Raining-Keras/dataset/rain/test_syn/*.jpg')\n",
    "vali_data = vali_data.map(load_test)\n",
    "vali_data = vali_data.batch(BATCH_SIZE)\n",
    "\n",
    "test_data = tf.data.Dataset.list_files('/content/drive/My Drive/Colab Notebooks/IDCGAN_Github/Single-Image-De-Raining-Keras/dataset/rain/val/*.jpg')\n",
    "test_data = test_data.map(load_test)\n",
    "test_data = test_data.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kdrGsylosZgr"
   },
   "outputs": [],
   "source": [
    "def down_sample(filters,size,apply_batchNorm=True):\n",
    "  result = tf.keras.Sequential()\n",
    "  result.add(tf.keras.layers.Conv2D(filters,size,strides=2,padding='same',\n",
    "                                    kernel_initializer=tf.random_normal_initializer(0.,0.02),\n",
    "                                    use_bias=False))\n",
    "  if apply_batchNorm:\n",
    "    result.add(tf.keras.layers.BatchNormalization())\n",
    "  result.add(tf.keras.layers.LeakyReLU())\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q6DqlxJiyaD6"
   },
   "outputs": [],
   "source": [
    "def up_sample(filters,size,apply_dropOut=False):\n",
    "  result = tf.keras.Sequential()\n",
    "  result.add(tf.keras.layers.UpSampling2D(size=(2, 2)))\n",
    "  result.add(tf.keras.layers.Conv2DTranspose(filters,size,strides=1,padding='same',\n",
    "                                    kernel_initializer=tf.random_normal_initializer(0.,0.02),\n",
    "                                    use_bias=False))\n",
    "  result.add(tf.keras.layers.BatchNormalization())\n",
    "  if apply_dropOut:\n",
    "    result.add(tf.keras.layers.Dropout(0.5))\n",
    "  result.add(tf.keras.layers.LeakyReLU())\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ki77eL_XzSM2"
   },
   "outputs": [],
   "source": [
    "def Generator():\n",
    "  inputs = tf.keras.layers.Input(shape=(256,256,3))\n",
    "\n",
    "  down_stack = [down_sample(64,4,apply_batchNorm=False), # (bs, 128, 128, 64)\n",
    "                down_sample(128,4), # (bs, 64, 64, 128)\n",
    "                down_sample(256,4), # (bs, 32, 32, 256)\n",
    "                down_sample(512,4), # (bs, 16, 16, 512)\n",
    "                down_sample(512,4), # (bs, 8, 8, 512)\n",
    "                down_sample(512,4), # (bs, 4, 4, 512)\n",
    "                down_sample(512,4), # (bs, 2, 2, 512)\n",
    "                down_sample(512,4)] # (bs, 1, 1, 512)\n",
    "\n",
    "  up_stack = [up_sample(512,4,apply_dropOut=True), # (bs, 2, 2, 1024)\n",
    "                up_sample(512,4,apply_dropOut=True), # (bs, 4, 4, 1024)\n",
    "                up_sample(512,4,apply_dropOut=True), # (bs, 8, 8, 1024)\n",
    "                up_sample(512,4), # (bs, 16, 16, 1024)\n",
    "                up_sample(256,4), # (bs, 32, 32, 512)\n",
    "                up_sample(128,4), # (bs, 64, 64, 256)\n",
    "                up_sample(64,4), # (bs, 128, 128, 128)\n",
    "                ]\n",
    "  last = tf.keras.layers.Conv2DTranspose(3,4,strides=2,padding='same',\n",
    "                                           kernel_initializer=tf.random_normal_initializer(0.,0.02),\n",
    "                                           activation='tanh')\n",
    "\n",
    "  x = inputs\n",
    "  skip_connections = []\n",
    "  for layer in down_stack:\n",
    "    x = layer(x)\n",
    "    skip_connections.append(x)\n",
    "  \n",
    "  skip_connections = reversed(skip_connections[:-1])\n",
    "\n",
    "  for layer, u_net in zip(up_stack,skip_connections):\n",
    "    x = layer(x)\n",
    "    x = tf.keras.layers.Add()([x, u_net])\n",
    "\n",
    "  out = last(x)\n",
    "\n",
    "  return tf.keras.Model(inputs=inputs,outputs=out)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "dvKIXea-zrhA",
    "outputId": "1e9bc2eb-2860-420f-fb22-c89cb9827c7f"
   },
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "tf.keras.utils.plot_model(generator,show_shapes=True,dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nxD4yG_oNCx6",
    "outputId": "64ca0349-a867-44da-eae6-75f80fe783a0"
   },
   "outputs": [],
   "source": [
    "print(fake.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "colab_type": "code",
    "id": "VVsHybAhp6Gj",
    "outputId": "0a66efba-6beb-4a13-d850-bbe385cc2b86"
   },
   "outputs": [],
   "source": [
    "gen_output = generator(fake[tf.newaxis,...], training=False)\n",
    "plt.imshow(gen_output[0,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fIge2ToP4FO4"
   },
   "outputs": [],
   "source": [
    "LAMBDA = 100\n",
    "def generator_loss(disc_generated_output, gen_output, target):\n",
    "  gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "  \n",
    "  # mean absolute error\n",
    "  l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
    "\n",
    "  total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n",
    "\n",
    "  return total_gen_loss, gan_loss, l1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fy2pkSy_5qvn"
   },
   "outputs": [],
   "source": [
    "def Discriminator():\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "  inp = tf.keras.layers.Input(shape=[256, 256, 3], name='input_image')\n",
    "  tar = tf.keras.layers.Input(shape=[256, 256, 3], name='target_image')\n",
    "\n",
    "  x = tf.keras.layers.concatenate([inp, tar]) # (bs, 256, 256, channels*2)\n",
    "\n",
    "  down1 = down_sample(64, 4, False)(x) # (bs, 128, 128, 64)\n",
    "  down2 = down_sample(128, 4)(down1) # (bs, 64, 64, 128)\n",
    "  down3 = down_sample(256, 4)(down2) # (bs, 32, 32, 256)\n",
    "\n",
    "  zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3) # (bs, 34, 34, 256)\n",
    "  conv = tf.keras.layers.Conv2D(512, 4, strides=1,\n",
    "                                kernel_initializer=initializer,\n",
    "                                use_bias=False)(zero_pad1) # (bs, 31, 31, 512)\n",
    "\n",
    "  batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n",
    "\n",
    "  leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n",
    "\n",
    "  zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu) # (bs, 33, 33, 512)\n",
    "\n",
    "  last = tf.keras.layers.Conv2D(1, 4, strides=1,\n",
    "                                kernel_initializer=initializer)(zero_pad2) # (bs, 30, 30, 1)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inp, tar], outputs=last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 804
    },
    "colab_type": "code",
    "id": "1Cm1OHF3U1_T",
    "outputId": "00ee9910-32d1-49ad-b6a2-bd99d63143b1"
   },
   "outputs": [],
   "source": [
    "discriminator = Discriminator()\n",
    "tf.keras.utils.plot_model(discriminator, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "colab_type": "code",
    "id": "-fyAJnjDVEmN",
    "outputId": "542b916c-94a8-407e-de30-b2e3995961f1"
   },
   "outputs": [],
   "source": [
    "disc_out = discriminator([fake[tf.newaxis,...], gen_output], training=False)\n",
    "print(type(disc_out))\n",
    "print(tf.shape(disc_out))\n",
    "plt.imshow(disc_out[0,...,-1], vmin=-20, vmax=20, cmap='RdBu_r')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0qnOX3jsWZ9v"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HLOgVsyPqStI"
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "  real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
    "\n",
    "  generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "  total_disc_loss = real_loss + generated_loss\n",
    "\n",
    "  return total_disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g80iWflBqS7r"
   },
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "xJjEoq4FqV9k",
    "outputId": "4d1e0ac2-28ab-4298-d9eb-44a17ea14246"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_path = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint_prefix = 'checkpoint/ckpt'\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(checkpoint, checkpoint_path, max_to_keep=2)\n",
    "\n",
    "checkpoint.restore(ckpt_manager.latest_checkpoint)\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "  print(\"Restaurado de {}\".format(ckpt_manager.latest_checkpoint))\n",
    "else:\n",
    "  print(\"Inicializando desde cero.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "voQ2bL-gqrn-"
   },
   "outputs": [],
   "source": [
    "def generate_images(model, test_input, tar):\n",
    "  prediction = model(test_input, training=True)\n",
    "  plt.figure(figsize=(15,15))\n",
    "\n",
    "  display_list = [test_input[0], tar[0], prediction[0]]\n",
    "  title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
    "\n",
    "  for i in range(3):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.title(title[i])\n",
    "    # getting the pixel values between [0, 1] to plot it.\n",
    "    plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "    plt.axis('off')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "IZWbMuhPqwbd",
    "outputId": "d09d0491-aa4b-4873-ab62-4d83aec4a311"
   },
   "outputs": [],
   "source": [
    "for example_input, example_target in test_data.take(1):\n",
    "  plt.imshow(example_input[0])\n",
    "  plt.show()\n",
    "  generate_images(generator, example_input, example_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z7RSozmtqyKz"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "import datetime\n",
    "log_dir=\"logs/\"\n",
    "\n",
    "summary_writer = tf.summary.create_file_writer(\n",
    "  log_dir + \"fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jcfPvVIWtJ7A"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(input_image, target, epoch):\n",
    "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "    gen_output = generator(input_image, training=True)\n",
    "\n",
    "    disc_real_output = discriminator([input_image, target], training=True)\n",
    "    disc_generated_output = discriminator([input_image, gen_output], training=True)\n",
    "\n",
    "    gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, target)\n",
    "    disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
    "\n",
    "  generator_gradients = gen_tape.gradient(gen_total_loss,\n",
    "                                          generator.trainable_variables)\n",
    "  discriminator_gradients = disc_tape.gradient(disc_loss,\n",
    "                                               discriminator.trainable_variables)\n",
    "\n",
    "  generator_optimizer.apply_gradients(zip(generator_gradients,\n",
    "                                          generator.trainable_variables))\n",
    "  discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n",
    "                                              discriminator.trainable_variables))\n",
    "\n",
    "  with summary_writer.as_default():\n",
    "    tf.summary.scalar('gen_total_loss', gen_total_loss, step=epoch)\n",
    "    tf.summary.scalar('gen_gan_loss', gen_gan_loss, step=epoch)\n",
    "    tf.summary.scalar('gen_l1_loss', gen_l1_loss, step=epoch)\n",
    "    tf.summary.scalar('disc_loss', disc_loss, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vYEHRt3YtLgQ"
   },
   "outputs": [],
   "source": [
    "def fit(train_ds, epochs, test_ds):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "    for example_input, example_target in test_ds.take(1):\n",
    "      generate_images(generator, example_input, example_target)\n",
    "    print(\"Epoch: \", epoch)\n",
    "\n",
    "    # Train\n",
    "    for n, (input_image, target) in train_ds.enumerate():\n",
    "      print('.', end='')\n",
    "      if (n+1) % 100 == 0:\n",
    "        print()\n",
    "      train_step(input_image, target, epoch)\n",
    "    print()\n",
    "\n",
    "    # saving (checkpoint) the model every 20 epochs\n",
    "    if (epoch + 1) % 20 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1,\n",
    "                                                        time.time()-start))\n",
    "  checkpoint.save(file_prefix = checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "XytdhsBDtOE3",
    "outputId": "ffd367dc-21a2-484c-fa76-b968fb4180b1"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {log_dir}\n",
    "!kill 7412"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "colab_type": "code",
    "id": "4pnwAxPMtRQA",
    "outputId": "f3434349-65b1-4a82-e37e-b0113ae3d2f6"
   },
   "outputs": [],
   "source": [
    "fit(train_data, EPOCHS, vali_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AjIuE3sZtZ_J"
   },
   "outputs": [],
   "source": [
    "!tensorboard dev upload --logdir  {log_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P09yJnQxtqMt"
   },
   "outputs": [],
   "source": [
    "display.IFrame(\n",
    "    src=\"https://tensorboard.dev/experiment/lZ0C6FONROaUMfjYkVyJqw\",\n",
    "    width=\"100%\",\n",
    "    height=\"1000px\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MrD7wUILtw8Q"
   },
   "outputs": [],
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(\"/content/drive/My Drive/Colab Notebooks/IDCGAN_Github/Single-Image-De-Raining-Keras/dataset/checkpoint/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "13lWKMoZt3Kh"
   },
   "outputs": [],
   "source": [
    "# Run the trained model on a few examples from the test dataset\n",
    "for inp, tar in test_dataset.take(100):\n",
    "  generate_images(generator, inp, tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SOos1SESzF7C"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "pix2pix_rain_GAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
